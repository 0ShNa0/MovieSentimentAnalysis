{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2d4e2600",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in /Users/shravaninag/opt/anaconda3/lib/python3.9/site-packages (3.7)\n",
      "Requirement already satisfied: joblib in /Users/shravaninag/opt/anaconda3/lib/python3.9/site-packages (from nltk) (1.1.0)\n",
      "Requirement already satisfied: click in /Users/shravaninag/opt/anaconda3/lib/python3.9/site-packages (from nltk) (8.0.4)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /Users/shravaninag/opt/anaconda3/lib/python3.9/site-packages (from nltk) (2022.3.15)\n",
      "Requirement already satisfied: tqdm in /Users/shravaninag/opt/anaconda3/lib/python3.9/site-packages (from nltk) (4.64.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install nltk \n"
    
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "26041d4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from scipy.sparse import dok_matrix\n",
    "# You can also use this section to suppress warnings generated by your code:\n",
    "def warn(*args, **kwargs):\n",
    "    pass\n",
    "import warnings\n",
    "warnings.warn = warn\n",
    "warnings.filterwarnings('ignore')\n",
    "warn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "53451c01",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_sample_and_class(data, class_=1,n_samples=5):\n",
    "\n",
    "    index=data[data['y']==class_]['X'].index[0:n_samples]\n",
    "\n",
    "    for i in index:\n",
    "        print(\"sample {} of class {}\".format(i,class_))\n",
    "        print(data[data['y']==class_]['X'][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "538975d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y</th>\n",
       "      <th>X</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>The Rock is destined to be the 21st Century '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>The gorgeously elaborate continuation of `` T...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Singer\\/composer Bryan Adams contributes a sl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>You 'd think by now America would have had en...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>Yet the act is still charming here .</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   y                                                  X\n",
       "0  1   The Rock is destined to be the 21st Century '...\n",
       "1  1   The gorgeously elaborate continuation of `` T...\n",
       "2  1   Singer\\/composer Bryan Adams contributes a sl...\n",
       "3  0   You 'd think by now America would have had en...\n",
       "4  1               Yet the act is still charming here ."
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=  pd.read_csv(\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBM-GPXX08RAEN/sentiment-text-threeclass/train.txt\",header=None, sep=\"\\\\|\\\\|\\\\|\",names=['y','X'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4bbdeaa7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample 0 of class 1\n",
      " The Rock is destined to be the 21st Century 's new `` Conan '' and that he 's going to make a splash even greater than Arnold Schwarzenegger , Jean-Claud Van Damme or Steven Segal .\n",
      "sample 1 of class 1\n",
      " The gorgeously elaborate continuation of `` The Lord of the Rings '' trilogy is so huge that a column of words can not adequately describe co-writer\\/director Peter Jackson 's expanded vision of J.R.R. Tolkien 's Middle-earth .\n",
      "sample 2 of class 1\n",
      " Singer\\/composer Bryan Adams contributes a slew of songs -- a few potential hits , a few more simply intrusive to the story -- but the whole package certainly captures the intended , er , spirit of the piece .\n",
      "sample 4 of class 1\n",
      " Yet the act is still charming here .\n",
      "sample 5 of class 1\n",
      " Whether or not you 're enlightened by any of Derrida 's lectures on `` the other '' and `` the self , '' Derrida is an undeniably fascinating and playful fellow .\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print_sample_and_class(df, class_=1,n_samples=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "80b0686c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "document:  The Rock is destined to be the 21st Century 's new `` Conan '' and that he 's going to make a splash even greater than Arnold Schwarzenegger , Jean-Claud Van Damme or Steven Segal .\n",
      "\n",
      " type: <class 'str'>\n"
     ]
    }
   ],
   "source": [
    "my_string=df['X'][0]\n",
    "print(\"document:\",my_string)\n",
    "print(\"\\n type:\",type(my_string))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a40d0237",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' The Rock '"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_string[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cfceb5d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The',\n",
       " 'Rock',\n",
       " 'is',\n",
       " 'destined',\n",
       " 'to',\n",
       " 'be',\n",
       " 'the',\n",
       " '21st',\n",
       " 'Century',\n",
       " \"'s\",\n",
       " 'new',\n",
       " '``',\n",
       " 'Conan',\n",
       " \"''\",\n",
       " 'and',\n",
       " 'that',\n",
       " 'he',\n",
       " \"'s\",\n",
       " 'going',\n",
       " 'to',\n",
       " 'make',\n",
       " 'a',\n",
       " 'splash',\n",
       " 'even',\n",
       " 'greater',\n",
       " 'than',\n",
       " 'Arnold',\n",
       " 'Schwarzenegger',\n",
       " ',',\n",
       " 'Jean-Claud',\n",
       " 'Van',\n",
       " 'Damme',\n",
       " 'or',\n",
       " 'Steven',\n",
       " 'Segal',\n",
       " '.']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_string.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dfbda7f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" the rock is destined to be the 21st century 's new `` conan '' and that he 's going to make a splash even greater than arnold schwarzenegger , jean-claud van damme or steven segal .\""
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_string.casefold()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ac7f05b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        the rock is destined to be the 21st century '...\n",
       "1        the gorgeously elaborate continuation of `` t...\n",
       "2        singer\\/composer bryan adams contributes a sl...\n",
       "3        you 'd think by now america would have had en...\n",
       "4                    yet the act is still charming here .\n",
       "                              ...                        \n",
       "8539                                      a real snooze .\n",
       "8540                                       no surprises .\n",
       "8541     we 've seen the hippie-turned-yuppie plot bef...\n",
       "8542     her fans walked out muttering words like `` h...\n",
       "8543                                  in this case zero .\n",
       "Name: X, Length: 8544, dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"X\"].str.casefold()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e1851acc",
   "metadata": {},
   "outputs": [],
   "source": [
    "good_words = ['love', 'good','excellent', 'great','charming']\n",
    "\n",
    "\n",
    "bad_words = ['hate', 'bad','brutal', 'damnable', 'deplorable', 'detestable', 'disastrous', 'dreadful']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3d5b5a64",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"score\"]=0\n",
    "for bad_word in bad_words:\n",
    "    df[\"score\"]-=df[\"X\"].str.casefold().str.count(bad_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "29410c3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for good_words in good_words:\n",
    "    df[\"score\"]+=df[\"X\"].str.casefold().str.count(good_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d7d092eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y</th>\n",
       "      <th>X</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>The Rock is destined to be the 21st Century '...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>The gorgeously elaborate continuation of `` T...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Singer\\/composer Bryan Adams contributes a sl...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>You 'd think by now America would have had en...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>Yet the act is still charming here .</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   y                                                  X  score\n",
       "0  1   The Rock is destined to be the 21st Century '...      1\n",
       "1  1   The gorgeously elaborate continuation of `` T...      0\n",
       "2  1   Singer\\/composer Bryan Adams contributes a sl...      0\n",
       "3  0   You 'd think by now America would have had en...      0\n",
       "4  1               Yet the act is still charming here .      1"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4bb802e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' Good fun , good action , good acting , good dialogue , good pace , good cinematography .'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[df[\"score\"].argmax(axis=0),'X']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a5b17bf0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' It is that rare combination of bad writing , bad direction and bad acting -- the trifecta of badness .'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[df[\"score\"].argmin(axis=0),'X']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ce90dc39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>y</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>-1</th>\n",
       "      <td>0.003021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.057882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.106094</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       score\n",
       "y           \n",
       "-1  0.003021\n",
       " 0  0.057882\n",
       " 1  0.106094"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby('y').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8108d085",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "y\n",
       "-1    AxesSubplot(0.125,0.125;0.775x0.755)\n",
       " 0    AxesSubplot(0.125,0.125;0.775x0.755)\n",
       " 1    AxesSubplot(0.125,0.125;0.775x0.755)\n",
       "Name: score, dtype: object"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAD4CAYAAAAAczaOAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAAWr0lEQVR4nO3df4zUdZ7n8efLhrONDYrQ08fY3MFk2F0aucG1Zb2YnWvOuYVjjLhxJ8HNjXBqeq+Dxsnp7eJsLutkQ2Jyt/PDqJ1jxzkx49oh8wuig7uumcrcJiKC52wPMIxkYJ0CDpFxlJ4EhZ73/VHfni2w6PrR9aOLz+uRVKq+n/p8vt/3h4ovv/Wpb1UrIjAzszRc1uoCzMyseRz6ZmYJceibmSXEoW9mlhCHvplZQma0uoBy5s2bFwsXLqxp7K9+9SuuvPLK+hY0zXnOaUhtzqnNF6Y+5717974TEd0Xtk/70F+4cCF79uypaWwul2NgYKC+BU1znnMaUptzavOFqc9Z0j+VavfyjplZQhz6ZmYJceibmSVk2q/pm5k1y9mzZ8nn85w5c6bVpXDVVVdx4MCBsv06Ozvp7e1l5syZFe3XoW9mlsnn88yaNYuFCxciqaW1nD59mlmzZk3aJyI4deoU+XyeRYsWVbRfL++YmWXOnDnD3LlzWx74lZLE3Llzq3pn4tA3MyvSLoE/odp6HfpmZgnxmr6Z2UUs3PRCXfd35NHPVtz3pz/9Kffddx+vv/46mzdv5qGHHqpLDQ59m9aWbV1Wts9Q1xD3b72/4n2Orh+dSklmTTFnzhwee+wxvve979V1v17eMTObhrq7u7nxxhsrvhSzUg59M7OEOPTNzBLi0DczmyaeeOIJli9fzvLlyzl+/HhDjuEPcs3MpomNGzeyceNGoPCN3EZw6JuZXUQ1l1jW24kTJ1iyZAnvv/8+l112GV/96lfZv38/s2fPntJ+HfpmZtNQT08P+Xy+7vv1mr6ZWULKhr6kTkm7Jf1I0j5JX8rar5H0kqQ3s/s5RWMelnRI0kFJq4rab5A0mj33mNrtRy7MzNpcJWf6HwD/PiI+BSwHVku6CdgEvBwRi4GXs20k9QHrgKXAauBJSR3ZvoaBQWBxdltdv6mYmVk5ZUM/CsayzZnZLYC1wNasfStwe/Z4LTASER9ExGHgELBC0nxgdkS8EhEBPFM0xszMmqCiD3KzM/W9wCeBJyLiVUk9EXEcICKOS/pY1v1aYFfR8HzWdjZ7fGF7qeMNUnhHQE9PD7lcruIJFRsbG6t5bLtq9zmPHn3vvO2hrqGyY7o7uivqN6Gd/30mtPvrXK1mzfeqq65q2KWS1RofH6+4ljNnzlT871NR6EfEOLBc0tXAdyVdN0n3Uuv0MUl7qeNtAbYA9Pf3x8DAQCVlfkQul6PWse2q3ee84YJfNZy1ZLjsmKGuIYbHyvebMHpH+//gWru/ztVq1nwPHDhQ9q9VNUslfzlrQmdnJ9dff31Ffau6ZDMifikpR2Et/oSk+dlZ/nzg7axbHlhQNKwXOJa195ZoNzObnh65qs77e69slxdffJEHHniAs2fPMjg4yKZNm+paQiVX73RnZ/hIugL4DPATYAewPuu2HtiePd4BrJN0uaRFFD6w3Z0tBZ2WdFN21c5dRWPMzJI3Pj7Oxo0b2blzJ6+99hrPPfcc+/fvr+sxKjnTnw9szdb1LwO2RcTzkl4Btkm6B3gL+BxAROyTtA3YD5wDNmbLQwBDwNPAFcDO7GZmZsDu3bv55Cc/ySc+8QlOnz7NunXr2L59O319fXU7RtnQj4h/BD6yWBQRp4BbLjJmM7C5RPseYLLPA8zMknX06FEWLPjn1fHe3l5effXVuh7D38g1M5smClezn6/e32F16JuZTRO9vb38/Oc//812Pp/n4x//eF2P4dA3M5smbrzxRt58800OHz7Mhx9+yMjICLfddltdj+Ff2TQzu5gKLrGspxkzZvD444+zatUqzp49y7333svSpUvre4y67s3MzKZkzZo1rFmzpqovZ1XDyztmZglx6JuZJcShb2aWEIe+mVlCHPpmZglx6JuZJcSXbJqZXcSyrcvqur/R9eX/lsPdd9/N888/z7x58+r+C5vgM30zs2llw4YNvPjiiw3bv0PfzGwa+fSnP80111zTsP079M3MEuLQNzNLiEPfzCwhDn0zs4T4kk0zs4uo5BLLervzzjvJ5XK888479Pb28qUvfYl77rmnbvt36JuZTSPPPfccgH9a2czMps6hb2aWEIe+mVmRiGh1CVWptt6yoS9pgaQfSDogaZ+kB7L2RyQdlfRGdltTNOZhSYckHZS0qqj9Bkmj2XOPSVJV1ZqZNVBnZyenTp1qm+CPCE6dOkVnZ2fFYyr5IPcc8GBEvC5pFrBX0kvZc1+JiP9Z3FlSH7AOWAp8HPh7Sb8VEePAMDAI7AK+D6wGdlZcrZlZA/X29pLP5zl58mSrS+HMmTMVhXlnZye9vb0V77ds6EfEceB49vi0pAPAtZMMWQuMRMQHwGFJh4AVko4AsyPiFQBJzwC349A3s2li5syZLFq0qNVlAJDL5bj++uvrvl9V8zZG0kLgh8B1wH8FNgDvA3sovBt4V9LjwK6I+GY25ikKwX4EeDQiPpO1/z7wZxFxa4njDFJ4R0BPT88NIyMjNU1ubGyMrq6umsa2q3af8+jR987b7ug8WnZMd0c3J8crPzPrm9tXdV3TTbu/ztVKbb4w9TmvXLlyb0T0X9he8XX6krqAbwNfiIj3JQ0DfwlEdv9XwN1AqXX6mKT9o40RW4AtAP39/TEwMFBpmefJ5XLUOrZdtfucN2x64bztWUuGy44Z6hpieKx8vwmjdzT/Czf11u6vc7VSmy80bs4VXb0jaSaFwH82Ir4DEBEnImI8In4N/DWwIuueBxYUDe8FjmXtvSXazcysSSq5ekfAU8CBiPhyUfv8om5/CPw4e7wDWCfpckmLgMXA7uyzgdOSbsr2eRewvU7zMDOzClSyvHMz8HlgVNIbWdsXgTslLaewRHME+BOAiNgnaRuwn8KVPxuzK3cAhoCngSsorPP7Q1wzsyaq5Oqdf6D0evz3JxmzGdhcon0PhQ+BzcysBfyNXDOzhDj0zcwS4tA3M0uIQ9/MLCEOfTOzhDj0zcwS4tA3M0uIQ9/MLCEOfTOzhDj0zcwS4tA3M0uIQ9/MLCEOfTOzhDj0zcwS4tA3M0uIQ9/MLCEOfTOzhDj0zcwS4tA3M0uIQ9/MLCEOfTOzhDj0zcwS4tA3M0uIQ9/MLCFlQ1/SAkk/kHRA0j5JD2Tt10h6SdKb2f2cojEPSzok6aCkVUXtN0gazZ57TJIaMy0zMyulkjP9c8CDEbEEuAnYKKkP2AS8HBGLgZezbbLn1gFLgdXAk5I6sn0NA4PA4uy2uo5zMTOzMsqGfkQcj4jXs8engQPAtcBaYGvWbStwe/Z4LTASER9ExGHgELBC0nxgdkS8EhEBPFM0xszMmkCF/K2ws7QQ+CFwHfBWRFxd9Ny7ETFH0uPAroj4Ztb+FLATOAI8GhGfydp/H/iziLi1xHEGKbwjoKen54aRkZGaJjc2NkZXV1dNY9tVu8959Oh75213dB4tO6a7o5uT4ycrPkbf3L6q65pu2v11rlZq84Wpz3nlypV7I6L/wvYZle5AUhfwbeALEfH+JMvxpZ6ISdo/2hixBdgC0N/fHwMDA5WWeZ5cLketY9tVu895w6YXztuetWS47JihriGGx8r3mzB6x2jVdU037f46Vyu1+ULj5lzR1TuSZlII/Gcj4jtZ84lsyYbs/u2sPQ8sKBreCxzL2ntLtJuZWZNUcvWOgKeAAxHx5aKndgDrs8frge1F7eskXS5pEYUPbHdHxHHgtKSbsn3eVTTGzMyaoJLlnZuBzwOjkt7I2r4IPApsk3QP8BbwOYCI2CdpG7CfwpU/GyNiPBs3BDwNXEFhnX9nfaZhZmaVKBv6EfEPlF6PB7jlImM2A5tLtO+h8CGwmZm1gL+Ra2aWEIe+mVlCHPpmZglx6JuZJcShb2aWEIe+mVlCHPpmZglx6JuZJcShb2aWEIe+mVlCHPpmZglx6JuZJcShb2aWEIe+mVlCHPpmZglx6JuZJcShb2aWEIe+mVlCHPpmZglx6JuZJcShb2aWEIe+mVlCHPpmZgkpG/qSviHpbUk/Lmp7RNJRSW9ktzVFzz0s6ZCkg5JWFbXfIGk0e+4xSar/dMzMbDKVnOk/Dawu0f6ViFie3b4PIKkPWAcszcY8Kakj6z8MDAKLs1upfZqZWQOVDf2I+CHwiwr3txYYiYgPIuIwcAhYIWk+MDsiXomIAJ4Bbq+xZjMzq9GMKYy9T9JdwB7gwYh4F7gW2FXUJ5+1nc0eX9hekqRBCu8K6OnpIZfL1VTg2NhYzWPbVbvP+cFl587b7ugcKjumu6Oboa7y/Sa087/PhHZ/nauV2nyhcXOuNfSHgb8EIrv/K+BuoNQ6fUzSXlJEbAG2APT398fAwEBNReZyOWod267afc4bNr1w3vasJcNlxwx1DTE8Vr7fhNE7Rquua7pp99e5WqnNFxo355qu3omIExExHhG/Bv4aWJE9lQcWFHXtBY5l7b0l2s3MrIlqCv1sjX7CHwITV/bsANZJulzSIgof2O6OiOPAaUk3ZVft3AVsn0LdZmZWg7LLO5KeAwaAeZLywF8AA5KWU1iiOQL8CUBE7JO0DdgPnAM2RsR4tqshClcCXQHszG5mZtZEZUM/Iu4s0fzUJP03A5tLtO8BrquqOjMzqyt/I9fMLCEOfTOzhDj0zcwS4tA3M0uIQ9/MLCEOfTOzhDj0zcwS4tA3M0uIQ9/MLCEOfTOzhDj0zcwS4tA3M0uIQ9/MLCEOfTOzhDj0zcwS4tA3M0uIQ9/MLCEOfTOzhDj0zcwS4tA3M0uIQ9/MLCEOfTOzhDj0zcwS4tA3M0tI2dCX9A1Jb0v6cVHbNZJekvRmdj+n6LmHJR2SdFDSqqL2GySNZs89Jkn1n46ZmU2mkjP9p4HVF7RtAl6OiMXAy9k2kvqAdcDSbMyTkjqyMcPAILA4u124TzMza7CyoR8RPwR+cUHzWmBr9ngrcHtR+0hEfBARh4FDwApJ84HZEfFKRATwTNEYMzNrkhk1juuJiOMAEXFc0sey9muBXUX98lnb2ezxhe0lSRqk8K6Anp4ecrlcTUWOjY3VPLZdtfucH1x27rztjs6hsmO6O7oZ6irfb0I7//tMaPfXuVqpzRcaN+daQ/9iSq3TxyTtJUXEFmALQH9/fwwMDNRUTC6Xo9ax7ard57xh0wvnbc9aMlx2zFDXEMNj5ftNGL1jtOq6ppt2f52rldp8oXFzrvXqnRPZkg3Z/dtZex5YUNSvFziWtfeWaDczsyaqNfR3AOuzx+uB7UXt6yRdLmkRhQ9sd2dLQacl3ZRdtXNX0RgzM2uSsss7kp4DBoB5kvLAXwCPAtsk3QO8BXwOICL2SdoG7AfOARsjYjzb1RCFK4GuAHZmNzMza6KyoR8Rd17kqVsu0n8zsLlE+x7guqqqMzOzuvI3cs3MEuLQNzNLiEPfzCwhDn0zs4Q49M3MEuLQNzNLiEPfzCwhDn0zs4Q49M3MEuLQNzNLiEPfzCwhDn0zs4Q49M3MEuLQNzNLiEPfzCwhDn0zs4Q49M3MEuLQNzNLiEPfzCwhDn0zs4Q49M3MEuLQNzNLiEPfzCwhUwp9SUckjUp6Q9KerO0aSS9JejO7n1PU/2FJhyQdlLRqqsWbmVl16nGmvzIilkdEf7a9CXg5IhYDL2fbSOoD1gFLgdXAk5I66nB8MzOrUCOWd9YCW7PHW4Hbi9pHIuKDiDgMHAJWNOD4ZmZ2EYqI2gdLh4F3gQD+V0RskfTLiLi6qM+7ETFH0uPAroj4Ztb+FLAzIr5VYr+DwCBAT0/PDSMjIzXVNzY2RldXV01j21W7z3n06HvnbXd0Hi07prujm5PjJys+Rt/cvqrrmm7a/XWuVmrzhanPeeXKlXuLVmB+Y8aUqoKbI+KYpI8BL0n6ySR9VaKt5P9xImILsAWgv78/BgYGaioul8tR69h21e5z3rDphfO2Zy0ZLjtmqGuI4bHy/SaM3jFadV3TTbu/ztVKbb7QuDlPaXknIo5l928D36WwXHNC0nyA7P7trHseWFA0vBc4NpXjm5lZdWoOfUlXSpo18Rj4A+DHwA5gfdZtPbA9e7wDWCfpckmLgMXA7lqPb2Zm1ZvK8k4P8F1JE/v5m4h4UdJrwDZJ9wBvAZ8DiIh9krYB+4FzwMaIGJ9S9WZmVpWaQz8ifgZ8qkT7KeCWi4zZDGyu9ZhmZjY1/kaumVlCHPpmZglx6JuZJWSq1+mbtZ1lW5fVfZ+j69v/2n9Lg8/0zcwS4tA3M0uIQ9/MLCEOfTOzhDj0zcwS4tA3M0uIQ9/MLCEOfTOzhDj0zcwS4tA3M0uIQ9/MLCEOfTOzhPgH18zqYOEFf9C9lCOPfrYJlZhNzmf6ZmYJ8Zm+1UUlZ7pm1no+0zczS4jP9M3q4EjnH//m8cIzf9PCSswm5zN9M7OEOPTNzBLi0DczS0jT1/QlrQa+BnQAX4+IR5tdg9XfrCWbWl2CmVWgqaEvqQN4AvgPQB54TdKOiNjfzDpsCh65qnT7on/V3DoSsGzrsos+N9Q1xP1b769pv6PrR2styS4BzT7TXwEcioifAUgaAdYCDv0qXey6+AeXnWNDFdfM+1uizXOx16z4yp/z+H+k1gCKiOYdTPojYHVE3Jttfx74vYi474J+g8BgtvnbwMEaDzkPeKfGse3Kc05DanNObb4w9Tn/64jovrCx2Wf6KtH2kf/rRMQWYMuUDybtiYj+qe6nnXjOaUhtzqnNFxo352ZfvZMHFhRt9wLHmlyDmVmymh36rwGLJS2S9C+AdcCOJtdgZpaspi7vRMQ5SfcBf0vhks1vRMS+Bh5yyktEbchzTkNqc05tvtCgOTf1g1wzM2stfyPXzCwhDn0zs4QkE/qSHpIUkua1upZGk/Q/JP1E0j9K+q6kq1tdUyNIWi3poKRDki7534GQtEDSDyQdkLRP0gOtrqlZJHVI+r+Snm91Lc0g6WpJ38r+Oz4g6d/Wa99JhL6kBRR++uGtVtfSJC8B10XEvwF+Cjzc4nrqrugnPf4j0AfcKamvtVU13DngwYhYAtwEbExgzhMeAA60uogm+hrwYkT8DvAp6jj3JEIf+Arwp5T4ItilKCL+LiLOZZu7KHwf4lLzm5/0iIgPgYmf9LhkRcTxiHg9e3yaQhBc29qqGk9SL/BZ4OutrqUZJM0GPg08BRARH0bEL+u1/0s+9CXdBhyNiB+1upYWuRvY2eoiGuBa4OdF23kSCMAJkhYC1wOvtriUZvgqhZO2X7e4jmb5BHAS+N/ZktbXJV1Zr51fEn8uUdLfA/+yxFN/DnwR+IPmVtR4k805IrZnff6cwpLAs82srUkq+kmPS5GkLuDbwBci4v1W19NIkm4F3o6IvZIGWlxOs8wAfhe4PyJelfQ1YBPw3+u187YXEZ8p1S5pGbAI+JEkKCxzvC5pRUT8vyaWWHcXm/MESeuBW4Fb4tL8MkaSP+khaSaFwH82Ir7T6nqa4GbgNklrgE5gtqRvRsR/anFdjZQH8hEx8S7uWxRCvy6S+nKWpCNAf0Rc0r/Wl/2hmi8D/y4iTra6nkaQNIPCh9S3AEcp/MTHHzf4G94tpcKZy1bgFxHxhRaX03TZmf5DEXFri0tpOEn/B7g3Ig5KegS4MiL+Wz32fUmc6dtHPA5cDryUvcPZFRH/pbUl1VcLftJjOrgZ+DwwKumNrO2LEfH91pVkDXI/8Gz2G2U/A/5zvXac1Jm+mVnqLvmrd8zM7J859M3MEuLQNzNLiEPfzCwhDn0zs4Q49M3MEuLQNzNLyP8HVYDz/kbgkfUAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df[[\"score\",\"y\"]].groupby('y')[\"score\"].hist(legend=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "23ac7bff",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['yhat']=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "07eefc71",
   "metadata": {},
   "outputs": [],
   "source": [
    "negative_label=df[['score']].sum(axis=1)<1\n",
    "pos_label=df[['score']].sum(axis=1)>-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "52d43085",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['yhat'][negative_label]=-1\n",
    "df['yhat'][pos_label]=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b6c4f7cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 1    3610\n",
       "-1    3310\n",
       " 0    1624\n",
       "Name: y, dtype: int64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['y'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d97ea1ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1900749063670412"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(df['yhat']==df['y'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9ea4c72f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset=pd.read_csv(\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBM-GPXX08RAEN/sentiment-text-threeclass/train.txt\",header=None, sep=\"\\\\|\\\\|\\\\|\",names=['y','X']) \n",
    "validation_dataset=pd.read_csv(\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBM-GPXX08RAEN/sentiment-text-threeclass/dev.txt\",header=None, sep=\"\\\\|\\\\|\\\\|\",names=['y','X']) \n",
    "test_dataset =pd.read_csv(\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBM-GPXX08RAEN/sentiment-text-threeclass/test.txt\",header=None, sep=\"\\\\|\\\\|\\\\|\",names=['y','X']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "02b06310",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e0bed5d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = [\n",
    "    'This is the first of document .',\n",
    "    'This document is the second document.',\n",
    "     'And this is the third one.',\n",
    "     'Is this the first document?' ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f9c6fe24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<4x10 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 22 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer=CountVectorizer()\n",
    "\n",
    "X_toy = vectorizer.fit_transform(corpus)\n",
    "X_toy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "065966cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['and',\n",
       " 'document',\n",
       " 'first',\n",
       " 'is',\n",
       " 'of',\n",
       " 'one',\n",
       " 'second',\n",
       " 'the',\n",
       " 'third',\n",
       " 'this']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer. get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9f47e8e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1, 1, 1, 1, 0, 0, 1, 0, 1],\n",
       "       [0, 2, 0, 1, 0, 0, 1, 1, 0, 1],\n",
       "       [1, 0, 0, 1, 0, 1, 0, 1, 1, 1],\n",
       "       [0, 1, 1, 1, 0, 0, 0, 1, 0, 1]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_toy.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ebf3cfd1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>and</th>\n",
       "      <th>document</th>\n",
       "      <th>first</th>\n",
       "      <th>is</th>\n",
       "      <th>of</th>\n",
       "      <th>one</th>\n",
       "      <th>second</th>\n",
       "      <th>the</th>\n",
       "      <th>third</th>\n",
       "      <th>this</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>This is the first of document .</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>This document is the second document.</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>And this is the third one.</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Is this the first document?</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       and  document  first  is  of  one  \\\n",
       "This is the first of document .          0         1      1   1   1    0   \n",
       "This document is the second document.    0         2      0   1   0    0   \n",
       "And this is the third one.               1         0      0   1   0    1   \n",
       "Is this the first document?              0         1      1   1   0    0   \n",
       "\n",
       "                                       second  the  third  this  \n",
       "This is the first of document .             0    1      0     1  \n",
       "This document is the second document.       1    1      0     1  \n",
       "And this is the third one.                  0    1      1     1  \n",
       "Is this the first document?                 0    1      0     1  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original_toy_df= pd.DataFrame(X_toy.toarray(),columns=vectorizer.get_feature_names(),index=corpus )\n",
    "original_toy_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c6bfc8cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import PredefinedSplit, GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "756d81b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset=pd.concat([train_dataset,validation_dataset],axis=0)\n",
    "from sklearn.model_selection import PredefinedSplit\n",
    "\n",
    "split_index = [-1]*train_dataset.shape[0] + [0]*validation_dataset.shape[0]\n",
    "pds = PredefinedSplit(test_fold = split_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b399332b",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer()\n",
    "X = vectorizer.fit_transform(dataset['X'])\n",
    "y=dataset['y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c8b722a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test=vectorizer.transform(test_dataset['X'])\n",
    "y_test=test_dataset[['y']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5c6a98cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {'penalty' : ['l1', 'l2'],'C' : np.logspace(-4, 4, 20)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "1bef8d9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=PredefinedSplit(test_fold=array([-1, -1, ...,  0,  0])),\n",
       "             estimator=LogisticRegression(),\n",
       "             param_grid={'C': array([1.00000000e-04, 2.63665090e-04, 6.95192796e-04, 1.83298071e-03,\n",
       "       4.83293024e-03, 1.27427499e-02, 3.35981829e-02, 8.85866790e-02,\n",
       "       2.33572147e-01, 6.15848211e-01, 1.62377674e+00, 4.28133240e+00,\n",
       "       1.12883789e+01, 2.97635144e+01, 7.84759970e+01, 2.06913808e+02,\n",
       "       5.45559478e+02, 1.43844989e+03, 3.79269019e+03, 1.00000000e+04]),\n",
       "                         'penalty': ['l1', 'l2']})"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = GridSearchCV(estimator = LogisticRegression(),cv=pds,param_grid=param_grid)\n",
    "clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e61fd574",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "highest accuracy in the validation accuracy  0.6194368755676658\n",
      "best hyperparameters: {'C': 0.23357214690901212, 'penalty': 'l2'}\n"
     ]
    }
   ],
   "source": [
    "clf.fit(X, y)\n",
    "print(\"highest accuracy in the validation accuracy \",clf.best_score_)\n",
    "print(\"best hyperparameters:\",clf.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "0bc7c5c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " best parameters accuracy score : 0.6497737556561086\n"
     ]
    }
   ],
   "source": [
    "print(\" best parameters accuracy score :\",clf.score(X_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "03b4e7bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=clf.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "cd961326",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  1,  1, ...,  1, -1, -1])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "5a4ff5ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importance=np.argsort(model.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "ad8587ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(j) or y= 0\n",
      "['solid' 'powerful' 'enjoyable' 'best' 'hilarious' 'fun' 'perfectly'\n",
      " 'charming' 'always' 'human']\n",
      "(j) or y= 1\n",
      "['offers' 'screen' 'imagine' 'thoroughly' 'crafted' 'impressive' 'going'\n",
      " 'frequently' 'watching' 'four']\n",
      "(j) or y= 2\n",
      "['suffers' 'dull' 'worst' 'mess' 'too' 'unfortunately' 'lack' 'less'\n",
      " 'plain' 'bad']\n"
     ]
    }
   ],
   "source": [
    "for class_ in range(3):\n",
    "    \n",
    "    print(\"(j) or y=\",class_)\n",
    "    print(np.array(vectorizer.get_feature_names())[feature_importance[class_,0:10]])\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "e59dafcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_feature_map(X):\n",
    "\n",
    "    word_types =set()\n",
    "    #Split string into words usig split() then apply(set) \n",
    "    for x in X.str.casefold().str.split().apply(set):\n",
    "        \n",
    "        word_types=word_types.union(x)\n",
    "    \n",
    "    # Create a dictionary keyed by word mapping it to an index\n",
    "    return   {word: idx for idx, word in enumerate(word_types)}\n",
    "\n",
    "word_to_idx = build_feature_map(train_dataset[\"X\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "ec0eb2c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def extract_features(word_to_idx, X):\n",
    "    D=len(word_to_idx)\n",
    "    N=X.shape[0]\n",
    "    words=set(word_to_idx.keys())\n",
    "    \n",
    "    features = dok_matrix((N, D))\n",
    "    for row,x in enumerate(X[0:]):\n",
    "        for word in x.split():\n",
    "            if word in words:\n",
    "                features[row,word_to_idx[word.casefold()]]+=1\n",
    "    return features\n",
    "\n",
    "X_train= extract_features(word_to_idx, train_dataset[\"X\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "bb8cc60a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation accuracy  0.5912806539509536\n",
      "test accuracy  0.6339366515837104\n"
     ]
    }
   ],
   "source": [
    "X_train= extract_features(word_to_idx, train_dataset[\"X\"])\n",
    "y_train=train_dataset[[\"y\"]]\n",
    "\n",
    "X_val=extract_features(word_to_idx, validation_dataset[\"X\"])\n",
    "y_val=validation_dataset[['y']]\n",
    "X_test=extract_features(word_to_idx, test_dataset[\"X\"])\n",
    "y_test=test_dataset[['y']]\n",
    "lr = LogisticRegression()\n",
    "lr.fit(X_train, y_train)\n",
    "print(\"validation accuracy \",lr.score(X_val,y_val))\n",
    "print(\"test accuracy \",lr.score(X_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "de5817ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/shravaninag/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "41576e23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\"]\n"
     ]
    }
   ],
   "source": [
    "print(stopwords.words('english')[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "85735ad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(stop_words=stopwords.words('english'))\n",
    "X_toy = vectorizer.fit_transform(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "80b7c9c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>document</th>\n",
       "      <th>first</th>\n",
       "      <th>one</th>\n",
       "      <th>second</th>\n",
       "      <th>third</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>This is the first of document .</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>This document is the second document.</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>And this is the third one.</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Is this the first document?</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       document  first  one  second  third\n",
       "This is the first of document .               1      1    0       0      0\n",
       "This document is the second document.         2      0    0       1      0\n",
       "And this is the third one.                    0      0    1       0      1\n",
       "Is this the first document?                   1      1    0       0      0"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_toy_df= pd.DataFrame(X_toy.toarray(),columns=vectorizer.get_feature_names(),index=corpus )\n",
    "new_toy_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "0cd4e4d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>document</th>\n",
       "      <th>first</th>\n",
       "      <th>is</th>\n",
       "      <th>the</th>\n",
       "      <th>this</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>This is the first of document .</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>This document is the second document.</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>And this is the third one.</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Is this the first document?</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       document  first  is  the  this\n",
       "This is the first of document .               1      1   1    1     1\n",
       "This document is the second document.         2      0   1    1     1\n",
       "And this is the third one.                    0      0   1    1     1\n",
       "Is this the first document?                   1      1   1    1     1"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min_df=2\n",
    "vectorizer = CountVectorizer(min_df=min_df)\n",
    "X_toy = vectorizer.fit_transform(corpus)\n",
    "new_toy_df= pd.DataFrame(X_toy.toarray(),columns=vectorizer.get_feature_names(),index=corpus )\n",
    "new_toy_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "6ef3dfc5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>and</th>\n",
       "      <th>document</th>\n",
       "      <th>first</th>\n",
       "      <th>is</th>\n",
       "      <th>of</th>\n",
       "      <th>one</th>\n",
       "      <th>second</th>\n",
       "      <th>the</th>\n",
       "      <th>third</th>\n",
       "      <th>this</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>This is the first of document .</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>This document is the second document.</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>And this is the third one.</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Is this the first document?</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       and  document  first  is  of  one  \\\n",
       "This is the first of document .          0         1      1   1   1    0   \n",
       "This document is the second document.    0         2      0   1   0    0   \n",
       "And this is the third one.               1         0      0   1   0    1   \n",
       "Is this the first document?              0         1      1   1   0    0   \n",
       "\n",
       "                                       second  the  third  this  \n",
       "This is the first of document .             0    1      0     1  \n",
       "This document is the second document.       1    1      0     1  \n",
       "And this is the third one.                  0    1      1     1  \n",
       "Is this the first document?                 0    1      0     1  "
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original_toy_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "80467b03",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_df=0.75\n",
    "vectorizer = CountVectorizer(max_df=0.75)\n",
    "X_toy = vectorizer.fit_transform(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "5cc76f2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>and</th>\n",
       "      <th>document</th>\n",
       "      <th>first</th>\n",
       "      <th>of</th>\n",
       "      <th>one</th>\n",
       "      <th>second</th>\n",
       "      <th>third</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>This is the first of document .</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>This document is the second document.</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>And this is the third one.</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Is this the first document?</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       and  document  first  of  one  second  \\\n",
       "This is the first of document .          0         1      1   1    0       0   \n",
       "This document is the second document.    0         2      0   0    0       1   \n",
       "And this is the third one.               1         0      0   0    1       0   \n",
       "Is this the first document?              0         1      1   0    0       0   \n",
       "\n",
       "                                       third  \n",
       "This is the first of document .            0  \n",
       "This document is the second document.      0  \n",
       "And this is the third one.                 1  \n",
       "Is this the first document?                0  "
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_toy_df= pd.DataFrame(X_toy.toarray(),columns=vectorizer.get_feature_names(),index=corpus )\n",
    "new_toy_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "f48046b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "69291fd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline(steps=[(\"CV\", CountVectorizer()),  (\"LR\", LogisticRegression())])\n",
    "param_grid = {\n",
    "    \"CV__stop_words\":[stopwords.words('english')[0:n] for n in range(1,150,50)],\n",
    "    \"CV__min_df\":[5**n for n in range(5)],\n",
    "    \"CV__max_df\":[0.6,0.9],\n",
    "    \"LR__penalty\":[\"l1\", \"l2\"]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "2cf65039",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=PredefinedSplit(test_fold=array([-1, -1, ...,  0,  0])),\n",
       "             estimator=Pipeline(steps=[('CV', CountVectorizer()),\n",
       "                                       ('LR', LogisticRegression())]),\n",
       "             param_grid={'CV__max_df': [0.6, 0.9],\n",
       "                         'CV__min_df': [1, 5, 25, 125, 625],\n",
       "                         'CV__stop_words': [['i'],\n",
       "                                            ['i', 'me', 'my', 'myself', 'we',\n",
       "                                             'our', 'ours', 'ourselves', 'you',\n",
       "                                             \"you're\", \"you've\", \"you'll\",\n",
       "                                             \"you'd\", 'your', 'yours',\n",
       "                                             'you...,\n",
       "                                             'him', 'his', 'himself', 'she',\n",
       "                                             \"she's\", 'her', 'hers', 'herself',\n",
       "                                             'it', \"it's\", 'its', 'itself', ...],\n",
       "                                            ['i', 'me', 'my', 'myself', 'we',\n",
       "                                             'our', 'ours', 'ourselves', 'you',\n",
       "                                             \"you're\", \"you've\", \"you'll\",\n",
       "                                             \"you'd\", 'your', 'yours',\n",
       "                                             'yourself', 'yourselves', 'he',\n",
       "                                             'him', 'his', 'himself', 'she',\n",
       "                                             \"she's\", 'her', 'hers', 'herself',\n",
       "                                             'it', \"it's\", 'its', 'itself', ...]],\n",
       "                         'LR__penalty': ['l1', 'l2']})"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = GridSearchCV(pipe, param_grid ,cv=pds)\n",
    "clf "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "a147cf1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=PredefinedSplit(test_fold=array([-1, -1, ...,  0,  0])),\n",
       "             estimator=Pipeline(steps=[('CV', CountVectorizer()),\n",
       "                                       ('LR', LogisticRegression())]),\n",
       "             param_grid={'CV__max_df': [0.6, 0.9],\n",
       "                         'CV__min_df': [1, 5, 25, 125, 625],\n",
       "                         'CV__stop_words': [['i'],\n",
       "                                            ['i', 'me', 'my', 'myself', 'we',\n",
       "                                             'our', 'ours', 'ourselves', 'you',\n",
       "                                             \"you're\", \"you've\", \"you'll\",\n",
       "                                             \"you'd\", 'your', 'yours',\n",
       "                                             'you...,\n",
       "                                             'him', 'his', 'himself', 'she',\n",
       "                                             \"she's\", 'her', 'hers', 'herself',\n",
       "                                             'it', \"it's\", 'its', 'itself', ...],\n",
       "                                            ['i', 'me', 'my', 'myself', 'we',\n",
       "                                             'our', 'ours', 'ourselves', 'you',\n",
       "                                             \"you're\", \"you've\", \"you'll\",\n",
       "                                             \"you'd\", 'your', 'yours',\n",
       "                                             'yourself', 'yourselves', 'he',\n",
       "                                             'him', 'his', 'himself', 'she',\n",
       "                                             \"she's\", 'her', 'hers', 'herself',\n",
       "                                             'it', \"it's\", 'its', 'itself', ...]],\n",
       "                         'LR__penalty': ['l1', 'l2']})"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(dataset['X'], y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "c909f61f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "highest accuracy in the validation 0.5967302452316077\n",
      "best hyperparameters : {'CV__max_df': 0.6, 'CV__min_df': 1, 'CV__stop_words': ['i'], 'LR__penalty': 'l2'}\n"
     ]
    }
   ],
   "source": [
    "print(\"highest accuracy in the validation\",clf.best_score_)\n",
    "print(\"best hyperparameters :\",clf.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "39152a87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " best parameters best parameters accuracy score : 0.639366515837104\n"
     ]
    }
   ],
   "source": [
    "print(\" best parameters best parameters accuracy score :\",clf.score(test_dataset['X'],y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "05257ff1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['This is the first of document .',\n",
       " 'This document is the second document.',\n",
       " 'And this is the third one.',\n",
       " 'Is this the first document?']"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "0eef6d2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer=CountVectorizer()\n",
    "X_toy = vectorizer.fit_transform(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "d77298b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>and</th>\n",
       "      <th>document</th>\n",
       "      <th>first</th>\n",
       "      <th>is</th>\n",
       "      <th>of</th>\n",
       "      <th>one</th>\n",
       "      <th>second</th>\n",
       "      <th>the</th>\n",
       "      <th>third</th>\n",
       "      <th>this</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>This is the first of document .</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>This document is the second document.</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>And this is the third one.</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Is this the first document?</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       and  document  first  is  of  one  \\\n",
       "This is the first of document .          0         1      1   1   1    0   \n",
       "This document is the second document.    0         2      0   1   0    0   \n",
       "And this is the third one.               1         0      0   1   0    1   \n",
       "Is this the first document?              0         1      1   1   0    0   \n",
       "\n",
       "                                       second  the  third  this  \n",
       "This is the first of document .             0    1      0     1  \n",
       "This document is the second document.       1    1      0     1  \n",
       "And this is the third one.                  0    1      1     1  \n",
       "Is this the first document?                 0    1      0     1  "
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_dataframe=pd.DataFrame(X_toy.toarray(),index=corpus,columns=vectorizer.get_feature_names())\n",
    "tf_dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "f9967722",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "479ca3af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>and</th>\n",
       "      <th>document</th>\n",
       "      <th>first</th>\n",
       "      <th>is</th>\n",
       "      <th>of</th>\n",
       "      <th>one</th>\n",
       "      <th>second</th>\n",
       "      <th>the</th>\n",
       "      <th>third</th>\n",
       "      <th>this</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>This is the first of document .</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.378357</td>\n",
       "      <td>0.467346</td>\n",
       "      <td>0.309332</td>\n",
       "      <td>0.592769</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.309332</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.309332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>This document is the second document.</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.687624</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.281089</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.538648</td>\n",
       "      <td>0.281089</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.281089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>And this is the third one.</th>\n",
       "      <td>0.511849</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.267104</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.511849</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.267104</td>\n",
       "      <td>0.511849</td>\n",
       "      <td>0.267104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Is this the first document?</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.469791</td>\n",
       "      <td>0.580286</td>\n",
       "      <td>0.384085</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.384085</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.384085</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            and  document     first        is  \\\n",
       "This is the first of document .        0.000000  0.378357  0.467346  0.309332   \n",
       "This document is the second document.  0.000000  0.687624  0.000000  0.281089   \n",
       "And this is the third one.             0.511849  0.000000  0.000000  0.267104   \n",
       "Is this the first document?            0.000000  0.469791  0.580286  0.384085   \n",
       "\n",
       "                                             of       one    second       the  \\\n",
       "This is the first of document .        0.592769  0.000000  0.000000  0.309332   \n",
       "This document is the second document.  0.000000  0.000000  0.538648  0.281089   \n",
       "And this is the third one.             0.000000  0.511849  0.000000  0.267104   \n",
       "Is this the first document?            0.000000  0.000000  0.000000  0.384085   \n",
       "\n",
       "                                          third      this  \n",
       "This is the first of document .        0.000000  0.309332  \n",
       "This document is the second document.  0.000000  0.281089  \n",
       "And this is the third one.             0.511849  0.267104  \n",
       "Is this the first document?            0.000000  0.384085  "
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(TfidfTransformer().fit_transform(tf_dataframe).toarray(),index=corpus,columns=vectorizer.get_feature_names())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "a2f21dc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "80759fab",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline(steps=[(\"CV\", TfidfVectorizer()),  (\"LR\", LogisticRegression())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "7b1058e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    \"CV__stop_words\":[stopwords.words('english')[0:n] for n in range(1,150,50)],\n",
    "    \"CV__min_df\":[5**n for n in range(5)],\n",
    "    \"CV__max_df\":[0.6,0.9],\n",
    "    \"LR__penalty\":[\"l1\", \"l2\"]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "a108ee41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=PredefinedSplit(test_fold=array([-1, -1, ...,  0,  0])),\n",
       "             estimator=Pipeline(steps=[('CV', TfidfVectorizer()),\n",
       "                                       ('LR', LogisticRegression())]),\n",
       "             param_grid={'CV__max_df': [0.6, 0.9],\n",
       "                         'CV__min_df': [1, 5, 25, 125, 625],\n",
       "                         'CV__stop_words': [['i'],\n",
       "                                            ['i', 'me', 'my', 'myself', 'we',\n",
       "                                             'our', 'ours', 'ourselves', 'you',\n",
       "                                             \"you're\", \"you've\", \"you'll\",\n",
       "                                             \"you'd\", 'your', 'yours',\n",
       "                                             'you...,\n",
       "                                             'him', 'his', 'himself', 'she',\n",
       "                                             \"she's\", 'her', 'hers', 'herself',\n",
       "                                             'it', \"it's\", 'its', 'itself', ...],\n",
       "                                            ['i', 'me', 'my', 'myself', 'we',\n",
       "                                             'our', 'ours', 'ourselves', 'you',\n",
       "                                             \"you're\", \"you've\", \"you'll\",\n",
       "                                             \"you'd\", 'your', 'yours',\n",
       "                                             'yourself', 'yourselves', 'he',\n",
       "                                             'him', 'his', 'himself', 'she',\n",
       "                                             \"she's\", 'her', 'hers', 'herself',\n",
       "                                             'it', \"it's\", 'its', 'itself', ...]],\n",
       "                         'LR__penalty': ['l1', 'l2']})"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = GridSearchCV(pipe, param_grid ,cv=pds)\n",
    "clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "0dd8cb5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=PredefinedSplit(test_fold=array([-1, -1, ...,  0,  0])),\n",
       "             estimator=Pipeline(steps=[('CV', TfidfVectorizer()),\n",
       "                                       ('LR', LogisticRegression())]),\n",
       "             param_grid={'CV__max_df': [0.6, 0.9],\n",
       "                         'CV__min_df': [1, 5, 25, 125, 625],\n",
       "                         'CV__stop_words': [['i'],\n",
       "                                            ['i', 'me', 'my', 'myself', 'we',\n",
       "                                             'our', 'ours', 'ourselves', 'you',\n",
       "                                             \"you're\", \"you've\", \"you'll\",\n",
       "                                             \"you'd\", 'your', 'yours',\n",
       "                                             'you...,\n",
       "                                             'him', 'his', 'himself', 'she',\n",
       "                                             \"she's\", 'her', 'hers', 'herself',\n",
       "                                             'it', \"it's\", 'its', 'itself', ...],\n",
       "                                            ['i', 'me', 'my', 'myself', 'we',\n",
       "                                             'our', 'ours', 'ourselves', 'you',\n",
       "                                             \"you're\", \"you've\", \"you'll\",\n",
       "                                             \"you'd\", 'your', 'yours',\n",
       "                                             'yourself', 'yourselves', 'he',\n",
       "                                             'him', 'his', 'himself', 'she',\n",
       "                                             \"she's\", 'her', 'hers', 'herself',\n",
       "                                             'it', \"it's\", 'its', 'itself', ...]],\n",
       "                         'LR__penalty': ['l1', 'l2']})"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(dataset['X'], y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "83740567",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "highest accuracy in the validation 0.6294277929155313\n",
      "best hyperparameters : {'CV__max_df': 0.6, 'CV__min_df': 1, 'CV__stop_words': ['i'], 'LR__penalty': 'l2'}\n"
     ]
    }
   ],
   "source": [
    "print(\"highest accuracy in the validation\",clf.best_score_)\n",
    "print(\"best hyperparameters :\",clf.best_params_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "7759eaeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " best parameters best parameters accuracy score : 0.6579185520361991\n"
     ]
    }
   ],
   "source": [
    "print(\" best parameters best parameters accuracy score :\",clf.score(test_dataset['X'],y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "012d4a99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " best parameters best parameters accuracy score : 0.6579185520361991\n"
     ]
    }
   ],
   "source": [
    "print(\" best parameters best parameters accuracy score :\",clf.score(test_dataset['X'],y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "760b592b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
